{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import yfinance as yf\n",
    "from tqdm import tqdm\n",
    "\n",
    "while 'notebooks' in os.getcwd():\n",
    "    os.chdir(\"..\")\n",
    "    \n",
    "from src.preprocessing.finbert.get_news import get_news, \\\n",
    "    filter_news_with_name, save_company_news_df,\\\n",
    "    read_company_news_df\n",
    "from src.preprocessing.finbert.sentiment import generate_sentiment_from_title,\\\n",
    "    generate_news_df\n",
    "\n",
    "api_key = '64d11b117233d0.77790833'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-22 16:07:22.766388: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-08-22 16:07:22.840586: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-08-22 16:07:22.841535: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-22 16:07:24.032195: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "\n",
    "finbert = BertForSequenceClassification.from_pretrained('yiyanghkust/finbert-tone',num_labels=3)\n",
    "tokenizer = BertTokenizer.from_pretrained('yiyanghkust/finbert-tone')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data acquisition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching news for Facebook...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:15<00:00,  1.29s/it]\n",
      "100%|██████████| 12/12 [00:12<00:00,  1.03s/it]\n",
      "100%|██████████| 12/12 [00:36<00:00,  3.01s/it]\n",
      "100%|██████████| 12/12 [00:28<00:00,  2.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3234 news were found related to FB ticker\n",
      "Generating sentiment for Facebook...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3234/3234 [04:44<00:00, 11.38it/s]\n"
     ]
    }
   ],
   "source": [
    "# companies = {\n",
    "#     \"GOOGL\" : \"Google\",\n",
    "#     \"SBUX\" : \"Starbucks\",\n",
    "#     \"ADBE\" : \"Adobe\"\n",
    "# }\n",
    "\n",
    "companies = {\n",
    "    \"FB\": \"Facebook\"\n",
    "}\n",
    "\n",
    "for ticker, usual_name in companies.items():\n",
    "    news_df = generate_news_df(\n",
    "        ticker = ticker,\n",
    "        usual_name = usual_name,\n",
    "        finbert= finbert,\n",
    "        tokenizer = tokenizer,\n",
    "    )\n",
    "\n",
    "    save_company_news_df(news_df,\n",
    "                         ticker)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_company_news_df(news_df,\n",
    "                     \"NVDA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/12 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:10<00:00,  1.16it/s]\n",
      "100%|██████████| 12/12 [00:11<00:00,  1.07it/s]\n",
      "100%|██████████| 12/12 [00:24<00:00,  2.03s/it]\n",
      "100%|██████████| 12/12 [00:34<00:00,  2.85s/it]\n"
     ]
    }
   ],
   "source": [
    "start_year = 2019\n",
    "end_year = 2023\n",
    "stock = \"NFLX\"\n",
    "\n",
    "news, news_complete = get_news(stock)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7293"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(news_complete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_with_name = filter_news_with_name(news_complete, 'Netflix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3526"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(news_with_name )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3526 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3526/3526 [04:58<00:00, 11.83it/s]\n"
     ]
    }
   ],
   "source": [
    "sentiment = generate_sentiment_from_title(\n",
    "    news_with_name,\n",
    "    tokenizer,\n",
    "    finbert\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df = pd.DataFrame(news_with_name)[[\"date\",\"title\",\"content\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df[\"sentiment\"] = sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_company_news_df(news_df,\n",
    "                     \"NFLX\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df = generate_news_df(\n",
    "    \n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
