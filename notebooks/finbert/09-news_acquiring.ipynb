{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import yfinance as yf\n",
    "from tqdm import tqdm\n",
    "\n",
    "while 'notebooks' in os.getcwd():\n",
    "    os.chdir(\"..\")\n",
    "    \n",
    "from src.preprocessing.finbert.get_news import get_news, \\\n",
    "    filter_news_with_name, save_company_news_df,\\\n",
    "    read_company_news_df\n",
    "from src.preprocessing.finbert.sentiment import generate_sentiment_from_title,\\\n",
    "    generate_news_df\n",
    "\n",
    "api_key = '64d11b117233d0.77790833'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-23 21:54:21.523860: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-08-23 21:54:21.569541: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-08-23 21:54:21.570557: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-23 21:54:22.696756: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "\n",
    "finbert = BertForSequenceClassification.from_pretrained('yiyanghkust/finbert-tone',num_labels=3)\n",
    "tokenizer = BertTokenizer.from_pretrained('yiyanghkust/finbert-tone')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data acquisition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "all_news = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching news for Meta...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:19<00:00,  1.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "876 news were found related to META ticker\n",
      "Generating sentiment for Meta...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 876/876 [01:06<00:00, 13.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching news for Google...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:31<00:00,  2.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1281 news were found related to GOOGL ticker\n",
      "Generating sentiment for Google...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1281/1281 [01:37<00:00, 13.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching news for Microsoft...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:33<00:00,  2.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2182 news were found related to MSFT ticker\n",
      "Generating sentiment for Microsoft...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2182/2182 [02:18<00:00, 15.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching news for Netflix...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:17<00:00,  1.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1008 news were found related to NFLX ticker\n",
      "Generating sentiment for Netflix...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1008/1008 [00:46<00:00, 21.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching news for NVIDIA...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:25<00:00,  2.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1687 news were found related to NVDA ticker\n",
      "Generating sentiment for NVIDIA...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1687/1687 [01:19<00:00, 21.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching news for Oracle...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:13<00:00,  1.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "348 news were found related to ORCL ticker\n",
      "Generating sentiment for Oracle...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 348/348 [00:15<00:00, 21.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching news for Tesla...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:34<00:00,  2.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3913 news were found related to TSLA ticker\n",
      "Generating sentiment for Tesla...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3913/3913 [03:08<00:00, 20.78it/s]\n"
     ]
    }
   ],
   "source": [
    "# companies = {\n",
    "#     \"GOOGL\" : \"Google\",\n",
    "#     \"SBUX\" : \"Starbucks\",\n",
    "#     \"ADBE\" : \"Adobe\"\n",
    "# }\n",
    "\n",
    "companies = {\n",
    "    # \"AAPL\": \"Apple\",\n",
    "    # \"ADBE\":\"Adobe\",\n",
    "    # \"AMZN\": \"Amazon\",\n",
    "    \"META\": \"Meta\",\n",
    "    \"GOOGL\": \"Google\",\n",
    "    \"MSFT\": \"Microsoft\",\n",
    "    \"NFLX\": \"Netflix\",\n",
    "    \"NVDA\" : \"NVIDIA\",\n",
    "    \"ORCL\" : \"Oracle\",\n",
    "    \"TSLA\" : \"Tesla\"\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "for ticker, usual_name in companies.items():\n",
    "    news_df = generate_news_df(\n",
    "        ticker = ticker,\n",
    "        usual_name = usual_name,\n",
    "        finbert= finbert,\n",
    "        tokenizer = tokenizer,\n",
    "        start_year=2023,\n",
    "        end_year=2024\n",
    "    )\n",
    "\n",
    "    all_news[ticker] = news_df\n",
    "    # save_company_news_df(news_df,\n",
    "    #                      ticker)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/META_news.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 16\u001b[0m\n\u001b[1;32m      1\u001b[0m companies \u001b[39m=\u001b[39m {\n\u001b[1;32m      2\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mAAPL\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mApple\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m      3\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mADBE\u001b[39m\u001b[39m\"\u001b[39m:\u001b[39m\"\u001b[39m\u001b[39mAdobe\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m \n\u001b[1;32m     13\u001b[0m }\n\u001b[1;32m     15\u001b[0m \u001b[39mfor\u001b[39;00m ticker \u001b[39min\u001b[39;00m companies : \n\u001b[0;32m---> 16\u001b[0m     old_news \u001b[39m=\u001b[39m read_company_news_df(\n\u001b[1;32m     17\u001b[0m         ticker\n\u001b[1;32m     18\u001b[0m     )\n\u001b[1;32m     20\u001b[0m     news_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat([old_news, all_news[ticker]])\\\n\u001b[1;32m     21\u001b[0m         \u001b[39m.\u001b[39mreset_index(drop \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     23\u001b[0m     save_company_news_df(news_df,\n\u001b[1;32m     24\u001b[0m                          ticker \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m2\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/projects/itau-quant-challenge/src/preprocessing/finbert/get_news.py:82\u001b[0m, in \u001b[0;36mread_company_news_df\u001b[0;34m(company)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mread_company_news_df\u001b[39m(\n\u001b[1;32m     80\u001b[0m     company: \u001b[39mstr\u001b[39m\n\u001b[1;32m     81\u001b[0m ):\n\u001b[0;32m---> 82\u001b[0m     df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_pickle(\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mdata/\u001b[39;49m\u001b[39m{\u001b[39;49;00mcompany\u001b[39m}\u001b[39;49;00m\u001b[39m_news.pkl\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m     83\u001b[0m     df[\u001b[39m\"\u001b[39m\u001b[39mdate\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mto_datetime(df[\u001b[39m\"\u001b[39m\u001b[39mdate\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m     85\u001b[0m     \u001b[39mreturn\u001b[39;00m df\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/io/pickle.py:190\u001b[0m, in \u001b[0;36mread_pickle\u001b[0;34m(filepath_or_buffer, compression, storage_options)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    125\u001b[0m \u001b[39mLoad pickled pandas object (or any object) from file.\u001b[39;00m\n\u001b[1;32m    126\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[39m4    4    9\u001b[39;00m\n\u001b[1;32m    188\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    189\u001b[0m excs_to_catch \u001b[39m=\u001b[39m (\u001b[39mAttributeError\u001b[39;00m, \u001b[39mImportError\u001b[39;00m, \u001b[39mModuleNotFoundError\u001b[39;00m, \u001b[39mTypeError\u001b[39;00m)\n\u001b[0;32m--> 190\u001b[0m \u001b[39mwith\u001b[39;00m get_handle(\n\u001b[1;32m    191\u001b[0m     filepath_or_buffer,\n\u001b[1;32m    192\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    193\u001b[0m     compression\u001b[39m=\u001b[39;49mcompression,\n\u001b[1;32m    194\u001b[0m     is_text\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    195\u001b[0m     storage_options\u001b[39m=\u001b[39;49mstorage_options,\n\u001b[1;32m    196\u001b[0m ) \u001b[39mas\u001b[39;00m handles:\n\u001b[1;32m    197\u001b[0m \n\u001b[1;32m    198\u001b[0m     \u001b[39m# 1) try standard library Pickle\u001b[39;00m\n\u001b[1;32m    199\u001b[0m     \u001b[39m# 2) try pickle_compat (older pandas version) to handle subclass changes\u001b[39;00m\n\u001b[1;32m    200\u001b[0m     \u001b[39m# 3) try pickle_compat with latin-1 encoding upon a UnicodeDecodeError\u001b[39;00m\n\u001b[1;32m    202\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    203\u001b[0m         \u001b[39m# TypeError for Cython complaints about object.__new__ vs Tick.__new__\u001b[39;00m\n\u001b[1;32m    204\u001b[0m         \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/io/common.py:865\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    856\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(\n\u001b[1;32m    857\u001b[0m             handle,\n\u001b[1;32m    858\u001b[0m             ioargs\u001b[39m.\u001b[39mmode,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    861\u001b[0m             newline\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    862\u001b[0m         )\n\u001b[1;32m    863\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    864\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[0;32m--> 865\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(handle, ioargs\u001b[39m.\u001b[39;49mmode)\n\u001b[1;32m    866\u001b[0m     handles\u001b[39m.\u001b[39mappend(handle)\n\u001b[1;32m    868\u001b[0m \u001b[39m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/META_news.pkl'"
     ]
    }
   ],
   "source": [
    "companies = {\n",
    "    \"AAPL\": \"Apple\",\n",
    "    \"ADBE\":\"Adobe\",\n",
    "    \"AMZN\": \"Amazon\",\n",
    "    \"META\": \"Meta\",\n",
    "    \"GOOGL\": \"Google\",\n",
    "    \"MSFT\": \"Microsoft\",\n",
    "    \"NFLX\": \"Netflix\",\n",
    "    \"NVDA\" : \"NVIDIA\",\n",
    "    \"ORCL\" : \"Oracle\",\n",
    "    \"TSLA\" : \"Tesla\"\n",
    "\n",
    "}\n",
    "\n",
    "for ticker in companies :\n",
    "    if ticker == \"META\": \n",
    "        old_news = read_company_news_df(\n",
    "            \"FB\"\n",
    "        )\n",
    "    else:\n",
    "        old_news = read_company_news_df(\n",
    "            ticker\n",
    "        )\n",
    "        \n",
    "    news_df = pd.concat([old_news, all_news[ticker]])\\\n",
    "        .reset_index(drop = True)\n",
    "\n",
    "    if ticker == \"META\":\n",
    "        save_company_news_df(news_df,\n",
    "                             \"FB_updated\")\n",
    "    \n",
    "    else:\n",
    "        save_company_news_df(news_df,\n",
    "                         ticker + \"_updated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_news = read_company_news_df(\n",
    "    \"AAPL\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiment_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-03 00:09:00+00:00</td>\n",
       "      <td>Apple, AAPL Investment Losses Alert: Bernstein...</td>\n",
       "      <td>NEW YORK, Jan.  02, 2019  (GLOBE NEWSWIRE) -- ...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-03 17:32:00+00:00</td>\n",
       "      <td>SHAREHOLDER ALERT: Bronstein, Gewirtz &amp; Grossm...</td>\n",
       "      <td>NEW YORK, Jan.  03, 2019  (GLOBE NEWSWIRE) -- ...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-02-22 12:40:00+00:00</td>\n",
       "      <td>Factors of Influence in 2019, Key Indicators a...</td>\n",
       "      <td>NEW YORK, Feb.  22, 2019  (GLOBE NEWSWIRE) -- ...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-04-01 12:25:00+00:00</td>\n",
       "      <td>Report: Developing Opportunities within Apple,...</td>\n",
       "      <td>NEW YORK, April  01, 2019  (GLOBE NEWSWIRE) --...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-04-01 12:25:00+00:00</td>\n",
       "      <td>Report: Developing Opportunities within Apple,...</td>\n",
       "      <td>NEW YORK, April  01, 2019  (GLOBE NEWSWIRE) --...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9100</th>\n",
       "      <td>2023-08-23T11:35:00+00:00</td>\n",
       "      <td>1 Thing Investors Should Know About Apple's Re...</td>\n",
       "      <td>Apple (NASDAQ: AAPL) has been a wonderful inve...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9101</th>\n",
       "      <td>2023-08-23T12:15:00+00:00</td>\n",
       "      <td>If You Trade Apple (And Even if You Don't) Thi...</td>\n",
       "      <td>We're talking stuff such as Fibonacci retracem...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9102</th>\n",
       "      <td>2023-08-23T14:30:00+00:00</td>\n",
       "      <td>Amid Slowing Growth, Apple's Ace in the Hole I...</td>\n",
       "      <td>Everyone knows Apple (NASDAQ: AAPL) for its ic...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9103</th>\n",
       "      <td>2023-08-23T14:33:21+00:00</td>\n",
       "      <td>1 Supercharged Growth Stock That's a Shoo-in t...</td>\n",
       "      <td>Multiple growth drivers, a rebounding gaming m...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9104</th>\n",
       "      <td>2023-08-23T15:01:00+00:00</td>\n",
       "      <td>Apple issues a surprise iPhone danger warning</td>\n",
       "      <td>Nearly 1.5 billion of us are iPhone users. Wit...</td>\n",
       "      <td>negative</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9105 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           date  \\\n",
       "0     2019-01-03 00:09:00+00:00   \n",
       "1     2019-01-03 17:32:00+00:00   \n",
       "2     2019-02-22 12:40:00+00:00   \n",
       "3     2019-04-01 12:25:00+00:00   \n",
       "4     2019-04-01 12:25:00+00:00   \n",
       "...                         ...   \n",
       "9100  2023-08-23T11:35:00+00:00   \n",
       "9101  2023-08-23T12:15:00+00:00   \n",
       "9102  2023-08-23T14:30:00+00:00   \n",
       "9103  2023-08-23T14:33:21+00:00   \n",
       "9104  2023-08-23T15:01:00+00:00   \n",
       "\n",
       "                                                  title  \\\n",
       "0     Apple, AAPL Investment Losses Alert: Bernstein...   \n",
       "1     SHAREHOLDER ALERT: Bronstein, Gewirtz & Grossm...   \n",
       "2     Factors of Influence in 2019, Key Indicators a...   \n",
       "3     Report: Developing Opportunities within Apple,...   \n",
       "4     Report: Developing Opportunities within Apple,...   \n",
       "...                                                 ...   \n",
       "9100  1 Thing Investors Should Know About Apple's Re...   \n",
       "9101  If You Trade Apple (And Even if You Don't) Thi...   \n",
       "9102  Amid Slowing Growth, Apple's Ace in the Hole I...   \n",
       "9103  1 Supercharged Growth Stock That's a Shoo-in t...   \n",
       "9104      Apple issues a surprise iPhone danger warning   \n",
       "\n",
       "                                                content sentiment  \\\n",
       "0     NEW YORK, Jan.  02, 2019  (GLOBE NEWSWIRE) -- ...   neutral   \n",
       "1     NEW YORK, Jan.  03, 2019  (GLOBE NEWSWIRE) -- ...   neutral   \n",
       "2     NEW YORK, Feb.  22, 2019  (GLOBE NEWSWIRE) -- ...   neutral   \n",
       "3     NEW YORK, April  01, 2019  (GLOBE NEWSWIRE) --...  positive   \n",
       "4     NEW YORK, April  01, 2019  (GLOBE NEWSWIRE) --...  positive   \n",
       "...                                                 ...       ...   \n",
       "9100  Apple (NASDAQ: AAPL) has been a wonderful inve...   neutral   \n",
       "9101  We're talking stuff such as Fibonacci retracem...   neutral   \n",
       "9102  Everyone knows Apple (NASDAQ: AAPL) for its ic...   neutral   \n",
       "9103  Multiple growth drivers, a rebounding gaming m...   neutral   \n",
       "9104  Nearly 1.5 billion of us are iPhone users. Wit...  negative   \n",
       "\n",
       "      sentiment_count  \n",
       "0                 0.0  \n",
       "1                 0.0  \n",
       "2                 0.0  \n",
       "3                 1.0  \n",
       "4                 1.0  \n",
       "...               ...  \n",
       "9100              NaN  \n",
       "9101              NaN  \n",
       "9102              NaN  \n",
       "9103              NaN  \n",
       "9104              NaN  \n",
       "\n",
       "[9105 rows x 5 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([old_news, all_news[\"AAPL\"]])\\\n",
    "    .reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/12 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:10<00:00,  1.16it/s]\n",
      "100%|██████████| 12/12 [00:11<00:00,  1.07it/s]\n",
      "100%|██████████| 12/12 [00:24<00:00,  2.03s/it]\n",
      "100%|██████████| 12/12 [00:34<00:00,  2.85s/it]\n"
     ]
    }
   ],
   "source": [
    "start_year = 2019\n",
    "end_year = 2023\n",
    "stock = \"NFLX\"\n",
    "\n",
    "news, news_complete = get_news(stock)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7293"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(news_complete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_with_name = filter_news_with_name(news_complete, 'Netflix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3526"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(news_with_name )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3526 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3526/3526 [04:58<00:00, 11.83it/s]\n"
     ]
    }
   ],
   "source": [
    "sentiment = generate_sentiment_from_title(\n",
    "    news_with_name,\n",
    "    tokenizer,\n",
    "    finbert\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df = pd.DataFrame(news_with_name)[[\"date\",\"title\",\"content\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df[\"sentiment\"] = sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_company_news_df(news_df,\n",
    "                     \"NFLX\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df = generate_news_df(\n",
    "    \n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
